---

## Global Sales Prediction and Analysis using XGBoost & Power BI

### ğŸ“Œ Project Overview

This project builds a **data-driven sales prediction system** using **XGBoost** and other regression algorithms.
It performs **data cleaning, feature engineering, EDA, model training, and evaluation**, followed by **business intelligence visualization in Power BI**.

The goal is to **predict future sales** and uncover **key drivers influencing sales performance** â€” helping businesses optimize pricing, forecast demand, and improve decision-making.

---

## âš™ï¸ Features

âœ… Automated data cleaning & preprocessing
âœ… Exploratory Data Analysis (EDA) with rich visualizations
âœ… Advanced feature engineering (price, customer, product, and temporal features)
âœ… Model training & comparison (Linear, Ridge, RF, GB, XGBoost)
âœ… Hyperparameter tuning with GridSearchCV
âœ… Performance evaluation (RÂ², RMSE, MAE)
âœ… Feature importance analysis (Top 15 predictive factors)
âœ… Integration with **Power BI dashboards** for interactive reporting

---

## ğŸ“‚ Project Structure

```
ğŸ“ Sales_Prediction_Project/
â”‚
â”œâ”€â”€ sales_data.csv                  # Raw dataset
â”œâ”€â”€ sales_prediction_model.py       # Main Python script
â”œâ”€â”€ Telecom_ChurnCleaned.csv        # (Optional) preprocessed dataset
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ powerbi_dashboard.pbix          # Power BI visualization dashboard
```

---

## ğŸ§° Requirements

| Library                 | Description                              |
| ----------------------- | ---------------------------------------- |
| `pandas`, `numpy`       | Data manipulation & numerical operations |
| `matplotlib`, `seaborn` | Visualization                            |
| `scikit-learn`          | Preprocessing, training & metrics        |
| `xgboost`               | Gradient boosting regressor              |
| `warnings`              | Handling warnings gracefully             |

---

## ğŸ–¥ï¸ Installation

```bash
pip install xgboost pandas scikit-learn matplotlib seaborn numpy
```

---

## ğŸ§® Workflow Summary

### 1ï¸âƒ£ Data Loading & Cleaning

* Import `sales_data.csv`
* Drop irrelevant columns (`ADDRESSLINE2`, `ADDRESSLINE3`, etc.)
* Handle missing values via median imputation
* Remove null postal codes
* Rename columns for clarity (e.g., `ADDRESSLINE1 â†’ ADDRESS`)

---

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)

Comprehensive visual analysis using `matplotlib` and `seaborn`:

* Sales distribution histogram
* Total sales by product line
* Average sales by year and quarter
* Quantity vs. Sales correlation
* Total sales by order status

ğŸ–¼ï¸ Example visuals:

* `Sales by Product Line`
* `Sales by Year`
* `Quantity Ordered vs Sales`

---

### 3ï¸âƒ£ Feature Engineering

Creation of **derived & aggregated features** to boost predictive power:

* **Price-based:** `PROFIT_MARGIN`, `PRICE_DISCOUNT`, `REVENUE_PER_UNIT`
* **Temporal:** `DAY_OF_WEEK`, `DAY_OF_MONTH`, `WEEK_OF_YEAR`
* **Customer-level:** total and average sales per customer
* **Product-level:** average and total sales per product line
* **Interaction:** `QTY_PRICE_INTERACTION`, `STATUS_MSRP_RATIO`

---

### 4ï¸âƒ£ Model Preparation

* Encode categorical variables using `LabelEncoder`
* Split dataset: 80% train / 20% test
* Apply `StandardScaler` for numerical normalization

---

### 5ï¸âƒ£ Model Training & Tuning

#### ğŸ§  Algorithms:

* Linear Regression
* Ridge Regression
* Random Forest Regressor
* Gradient Boosting Regressor
* **XGBoost Regressor (Tuned)**

#### ğŸ¯ Hyperparameter Optimization:

Grid search with:

```python
param_grid = {
    'n_estimators': [100, 150],
    'max_depth': [5, 7],
    'learning_rate': [0.01, 0.1]
}
```

Best model achieved:

* **RÂ² (Test): â‰ˆ 0.81**
* **RMSE: Low error variance**
* **MAE: Stable across predictions**

---

### 6ï¸âƒ£ Model Evaluation

Metrics:

* **RÂ² Score**
* **RMSE (Root Mean Square Error)**
* **MAE (Mean Absolute Error)**

Comparison table printed as:

```
| Model              | Train RÂ² | Test RÂ² | RMSE ($) | MAE ($) |
|--------------------|----------|---------|-----------|---------|
| Linear Regression  | 0.73     | 0.70    | 1750.32   | 1210.21 |
| XGBoost (Tuned)    | 0.86     | 0.81    | 1250.10   | 920.55  |
```

---

### 7ï¸âƒ£ Feature Importance

Top predictive factors identified by XGBoost:

1. `PRICEEACH`
2. `QUANTITYORDERED`
3. `CUSTOMER_TOTAL_SALES`
4. `REVENUE_PER_UNIT`
5. `PRODUCTLINE_TOTAL_SALES`

Bar chart generated for top 15 features.

---

### 8ï¸âƒ£ Predictions Visualization

Includes:

* Actual vs. Predicted (Train/Test)
* Residual distribution
* Model comparison (RÂ² & RMSE)

---

## ğŸ“Š Power BI Integration

After model training, the processed dataset and predictions are exported for visualization.

### Steps:

1. Export model predictions:

   ```python
   predictions_df = pd.DataFrame({
       'Actual_Sales': y_test,
       'Predicted_Sales': y_pred_xgb_test
   })
   predictions_df.to_csv('sales_predictions_output.csv', index=False)
   ```

2. Import `sales_predictions_output.csv` into Power BI.

3. Create the following visuals:

   * ğŸ“ˆ **Actual vs Predicted Sales (Scatter)**
   * ğŸ“Š **Top 10 Customers by Sales**
   * ğŸ’¡ **Feature Importance Breakdown**
   * ğŸŒ **Sales by Country & Product Line (Map)**
   * â³ **Sales Trend by Year & Quarter**

4. Publish the Power BI dashboard (`powerbi_dashboard.pbix`) for stakeholders.

---

## ğŸ“ˆ Results Summary

* Best Model: **XGBoost**
* Test RÂ² â‰ˆ **0.81**
* RMSE: **Low deviation from actuals**
* Feature insights aligned with sales patterns (pricing, quantity, customer loyalty)
* Power BI visualizations deliver business interpretability

---

## ğŸš€ Future Enhancements

* Integrate with real-time sales API (e.g., Salesforce)
* Deploy model via Flask or FastAPI
* Automate data refresh and Power BI update
* Add time-series forecasting (Prophet or LSTM)

---